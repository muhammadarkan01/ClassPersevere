Mon, 28 Mar

saya mengikuti pembelajaran 

sesi I Data science:
- Dimensionality Reduction / pengurangan dimensi 
- Dimensionali AI
- Tujuan PCA ( principal component analysis)
- teknik terbagi menjadi 2 ( seleksi featue , feature extraction)
- PCA proses
- Hands on
- Mathematic approach to PCA
- Teknik LDA ( Linear Discriminant Analisis)

sesi II:
mengikuti pembelajaran NLP:
sesi I:
- mereview materi pertemuan sebelumnya
- proses NLP: akuisisi data, teks cleaning, teks processing, feature engineering, modelling, evaluasi performa model, deployment)
- Hands on

Tue, 29 Mar

mengikuti pembelajaran 
Sesi I  Computer Vision :
-	Image Segmention.
-	Implementasi Image Thresholding.
-	Implementasi Image Segmention dengan menggunakan Image Filtering/Pemfilteran Citra.
-	Implementasi Image Segmention dengan menggunakan Edge Detection/Deteksi Tepi.
- Deep learning & CNN

Sesi II  Reinforcement  learning
-	Konsep Monte Carlo (MC)
-	Elemen Algoritme MC
-	Algoritme MC
       => (First-Visit)
       => (Every fisit)

Wed, 30 Mar

saya mengikuti pembelajaran 

sesi 1 data science :
- Recomender sistem => memberikan informasi berupa saran objek yang kemungkinan  diminati / dibutuhkan pengguna
- colaborative filtering
- 2  pendekatan (memory-based dan model-based)
- Market Basket Analysis (MBA)
- Algoritma Apriori
-Hands on

sesi  II :
mengikuti pembelajaran NLP
- Text classification
-Nlp recap
-implementasi text calssification ( email/sms, sentimen anaalisis, emotion detection dll)
- pendekatan text classification ( ML, Lexicon-based)
-ML Approach 
-Lexicon-based  Approach
- proses text classification
-Hands on 

Thu, 31 Mar

saya mengikuti pembelajaran
sesi 1:
- Implementasi Object Detection Using CNN.
- Stacked CNN Architecture.

Sesi II :
- Data Visualization Technical Domain.
- Data Visualization => representasi grafis dari informasi dan data.
- Pentingnya visualisasi data.
- Datasaurus Dataset.
- Jenis Visualisasi data => statis, beranimasi dan interaktif.
- Dimensi dan Metrik => Atribut data dan pengukuran kuantitatif.
- Granularitas Data => tingkat ketelitian dalam sebuah model data atau proses pengambilan keputusan.
- Google Data Studio => Koneksi Sumber Data pada GDS, Tampilan Awal GDS, Tampilan Editor GDS.
- Tipe Charts di GDS => Table, Scorecard, Time Series, Bar, Pie, Google Maps, Geo Chart, Line, Area, Scatter, Pivot Table, Bullet, Treemap, dan Gauge.
- Implemetasi Orbit Student Dataset.
- Proposal Learning Plan - Technical AI Mastery 

Fri, 1 Apr

saya mengikuti  pembelajaran 
Sesi 1 

-	RECAP DL dan Mc memakaivalue Function = Expexted  Return Namun menggunakan pendekatan yang berbeda seperti value function,DP
-	DL dan Mc memakaivalue Function = Expexted  Return Namun menggunakan pendekatan yang berbeda seperti value function,DP dan Mc
-	Bootstrapping [1]Ch4,setiap kali value v(s) diperbaharui  (dalam policy evaluation) dari value satate berikutnya v(s).Atrtinya pembaharuan diperkirakan berdasarkan perkiraan state lainnya.
-	Bootstrapping dilakukan pada algoritm DP, sedangkan MC melakukan rata rata terhadap return untuk memperbaharui value
-	TD menggunakna bootstrapping sementara monte carlo tidak
-	TDL (tempral  difference learning -> mengestimasi reward  pada setiap Langkah (step)
-	Model based vs model  free methods
-	Intrduction TDL
-	Kelemahan model basse RL -> jumlah state dan action hasurslah terbatas,  dan mudah dijelaskan menggunakan transiton probability
-	Unutk masaslah non stationary, lebih baik kita “agak”melupakan episode yang lampau dengan mengganti  1/N(St) dengan a.
-	TD (0)
-	TD Control – SARSA
-	Hands On dan SARSA

Sesi 2 :
-	Web scraping, praktik pengumpulan data dari situs web melalui cara papun selain dari menggunakan program 
-	Etika web scraping , jika data yang digunakans ecara personal, dan dalam pengunaan wajar undang undang hak cipta , biasanya tidak ada masalah
-	Urllib3, library python lain yang digunakanntuk mengambil data dari URL, mirip dengan request library. Library ini sangat sederhana .
-	Beautiful soup module, library [ython yang dirancang untuk proyek seperti web scraping.
-	Scraping module, kerangka  kerja web crawling oper=n source yang cepat dan dibuat dengan python, dgunakan untuk mengekstrak data dari halaman web dengan bantuan penyeleksi berdasarkan Xpath, sifatnya umum.
-	Selenium, suatu kumpulan aplikasi open source untuk pengujian otomatis aplikasi web di berbagai browser dan plaform, bukan merupakan satu tool saja, melainkan kumpulan dari aplikasi.
-	Preparation, jika kita menargetkansitus web untuk mengambil data, perlu memahami skala dan strukturnya.
-	Preparation analyzing robots.txt,digunakan untuk menentukan bagian mana dari stus web yang diizinkan untuk dilakukan web scraping dan mana yang tidak.file ini tidak memiliki format standar.
-	Preparation analyzing sitemap files, jika ingin menelusuri web untukkonten baru, perlu mengecek  setipa halaman web untuk mengumpulkan
-	Preparation checking website size , jika hanya ada sedikt halaman online untuk ditelusuri, efisiensi bukanlah masalah utama, tapi jika situs  web berisi jutaan halaman web seperti en.wikipedia.org, menguduh setiap halaman web secara berurutan akan memakan waktu yang lama dan efisien akan menjadi perhatian utama.
-	Preparation analyzing technology used, ada modul Bernama builtwith yang dapaat digunakan untuk mempelajari
-	Preparation knowing ownerof website, protocol whois dapat digunakan untuk mengecek untuk siapa pemilik website, dengan implementasi padapython data menginstall python whois
-	Static web , sesuatu yang tidak berubah , halaman pertama di wolrd wide web Sebagian besar statis  dan tidak berubah.
-	Static web scraping, dengan web browser, kita dapat langsung mengetikan alamat web yang ingin dituju kemudian tekan enter.
-	Dynamic web, tugas yang kompleks dan kerumitannya berlipat
-	Http response,  kode status respon HTTP menunjukkan apakah permintaan HTTP tertentu berhasil diselesaikan atau tidak.
-	Storing data media, untuk membuat web scraping berguna,  perlu dapat
-	By reference, kita dapat mmenyimpan flie by reference dengan menyimpan URL tempat file tersebut berada.

What did you learn this week?

mingggu ini saya telah mengikuti pembelajaran 5 domain dengan 2 sesi

Data science 
- Dimensionality Reduction / pengurangan dimensi 
- Dimensionali AI
- Tujuan PCA ( principal component analysis)
- teknik terbagi menjadi 2 ( seleksi featue , feature extraction)
- PCA proses
- Hands on
- Mathematic approach to PCA
- Teknik LDA ( Linear Discriminant Analisis)
- Recomender sistem => memberikan informasi berupa saran objek yang kemungkinan  diminati / dibutuhkan pengguna
- colaborative filtering
- 2  pendekatan (memory-based dan model-based)
- Market Basket Analysis (MBA)
- Algoritma Apriori
- mengikuti handson

Natural language processing
- mereview materi pertemuan sebelumnya
- proses NLP: akuisisi data, teks cleaning, teks processing, feature engineering, modelling, evaluasi performa model, deployment)
- Hands on
- Text classification
-Nlp recap
-implementasi text calssification ( email/sms, sentimen anaalisis, emotion detection dll)
- pendekatan text classification ( ML, Lexicon-based)
-ML Approach 
-Lexicon-based  Approach
- proses text classification

Computer vision 
-	Image Segmention.
-	Implementasi Image Thresholding.
-	Implementasi Image Segmention dengan menggunakan Image Filtering/Pemfilteran Citra.
-	Implementasi Image Segmention dengan menggunakan Edge Detection/Deteksi Tepi.
- Deep learning & CNN
- Implementasi Object Detection Using CNN.
- Stacked CNN Architecture.

Reinforcement Learning
-	Konsep Monte Carlo (MC)
-	Elemen Algoritme MC
-	Algoritme MC
       => (First-Visit)
       => (Every fisit)
	RECAP DL dan Mc memakaivalue Function = Expexted  Return Namun menggunakan pendekatan yang berbeda seperti value function,DP
-	DL dan Mc memakaivalue Function = Expexted  Return Namun menggunakan pendekatan yang berbeda seperti value function,DP dan Mc
-	Bootstrapping [1]Ch4,setiap kali value v(s) diperbaharui  (dalam policy evaluation) dari value satate berikutnya v(s).Atrtinya pembaharuan diperkirakan berdasarkan perkiraan state lainnya.
-	Bootstrapping dilakukan pada algoritm DP, sedangkan MC melakukan rata rata terhadap return untuk memperbaharui value
-	TD menggunakna bootstrapping sementara monte carlo tidak
-	TDL (tempral  difference learning -> mengestimasi reward  pada setiap Langkah (step)
-	Model based vs model  free methods
-	Intrduction TDL
-	Kelemahan model basse RL -> jumlah state dan action hasurslah terbatas,  dan mudah dijelaskan menggunakan transiton probability
-	Unutk masaslah non stationary, lebih baik kita “agak”melupakan episode yang lampau dengan mengganti  1/N(St) dengan a.
-	TD (0)
-	TD Control – SARSA
-	Hands On dan SARSA

Technical 
- Data Visualization => representasi grafis dari informasi dan data.
- Pentingnya visualisasi data.
- Datasaurus Dataset.
- Jenis Visualisasi data => statis, beranimasi dan interaktif.
- Dimensi dan Metrik => Atribut data dan pengukuran kuantitatif.
- Granularitas Data => tingkat ketelitian dalam sebuah model data atau proses pengambilan keputusan.
- Google Data Studio => Koneksi Sumber Data pada GDS, Tampilan Awal GDS, Tampilan Editor GDS.
- Tipe Charts di GDS => Table, Scorecard, Time Series, Bar, Pie, Google Maps, Geo Chart, Line, Area, Scatter, Pivot Table, Bullet, Treemap, dan Gauge.
- Implemetasi Orbit Student Dataset.
- Proposal Learning Plan - Technical AI Mastery 
-	Web scraping, praktik pengumpulan data dari situs web melalui cara papun selain dari menggunakan program 
-	Etika web scraping , jika data yang digunakans ecara personal, dan dalam pengunaan wajar undang undang hak cipta , biasanya tidak ada masalah
-	Urllib3, library python lain yang digunakanntuk mengambil data dari URL, mirip dengan request library. Library ini sangat sederhana .
-	Beautiful soup module, library [ython yang dirancang untuk proyek seperti web scraping.
-	Scraping module, kerangka  kerja web crawling oper=n source yang cepat dan dibuat dengan python, dgunakan untuk mengekstrak data dari halaman web dengan bantuan penyeleksi berdasarkan Xpath, sifatnya umum.
-	Selenium, suatu kumpulan aplikasi open source untuk pengujian otomatis aplikasi web di berbagai browser dan plaform, bukan merupakan satu tool saja, melainkan kumpulan dari aplikasi.
-	Preparation, jika kita menargetkansitus web untuk mengambil data, perlu memahami skala dan strukturnya.
-	Preparation analyzing robots.txt,digunakan untuk menentukan bagian mana dari stus web yang diizinkan untuk dilakukan web scraping dan mana yang tidak.file ini tidak memiliki format standar.
-	Preparation analyzing sitemap files, jika ingin menelusuri web untukkonten baru, perlu mengecek  setipa halaman web untuk mengumpulkan
-	Preparation checking website size , jika hanya ada sedikt halaman online untuk ditelusuri, efisiensi bukanlah masalah utama, tapi jika situs  web berisi jutaan halaman web seperti en.wikipedia.org, menguduh setiap halaman web secara berurutan akan memakan waktu yang lama dan efisien akan menjadi perhatian utama.
-	Preparation analyzing technology used, ada modul Bernama builtwith yang dapaat digunakan untuk mempelajari
-	Preparation knowing ownerof website, protocol whois dapat digunakan untuk mengecek untuk siapa pemilik website, dengan implementasi padapython data menginstall python whois
-	Static web , sesuatu yang tidak berubah , halaman pertama di wolrd wide web Sebagian besar statis  dan tidak berubah.
-	Static web scraping, dengan web browser, kita dapat langsung mengetikan alamat web yang ingin dituju kemudian tekan enter.
-	Dynamic web, tugas yang kompleks dan kerumitannya berlipat
-	Http response,  kode status respon HTTP menunjukkan apakah permintaan HTTP tertentu berhasil diselesaikan atau tidak.
-	Storing data media, untuk membuat web scraping berguna,  perlu dapat
-	By reference, kita dapat mmenyimpan flie by reference dengan menyimpan URL tempat file tersebut berada.
